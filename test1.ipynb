{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We start by importing the relevant libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scapy.all import *\n",
    "import numpy as np\n",
    "import graphviz\n",
    "from graphviz import Source"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We load the pcap file and split it into Packets and Frames:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_traffic = rdpcap(\"./pcap/network-traffic.pcap\")\n",
    "packet_list = []\t\t# to store layer 3 traffic\n",
    "frame_list = []\t\t\t# to store layer 2 traffic\n",
    "for packet in all_traffic:\n",
    "\tif (IP in packet):\n",
    "\t\tpacket_list.append(packet)\t\n",
    "\telse:\n",
    "\t\tframe_list.append(packet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We filter the frames, we are interested in source, destination and size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_frames = []\n",
    "for frame in frame_list:\n",
    "\tfiltered_frames.append([frame['Ether'].src + ',' + frame['Ether'].dst, len(frame)])\n",
    "matrix_ff = np.array(filtered_frames)\t\t# matrix of filtered frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We filter the packets, we are interested in only source, destination and size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_packets = []\n",
    "for packet in packet_list:\n",
    "\tfiltered_packets.append([packet['IP'].src + ',' + packet['IP'].dst, len(packet)])\n",
    "matrix_fp = np.array(filtered_packets)\t\t# matrix of filtered packets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify the conversation (communication between end points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "ethernet_conversation = list(set(matrix_ff[:,0]))\n",
    "size_ether = [0] * len(ethernet_conversation)\n",
    "matrix_ethernet_conv = np.array([ethernet_conversation, size_ether])\n",
    "matrix_ethernet_conv = np.transpose(matrix_ethernet_conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation_list = list(set(matrix_fp[:,0]))\n",
    "size_list = [0] * len(conversation_list)\n",
    "matrix_conversations = np.array([conversation_list, size_list])\t\t# size_list gets casted to string =(\n",
    "matrix_conversations = np.transpose(matrix_conversations)\t\t\t# change first column to the IP addresses and second column to size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculation of the conversation size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(matrix_ethernet_conv)):\n",
    "\tconversation_size = 0\n",
    "\tfor j in range(len(matrix_ff[:,0])):\n",
    "\t\tif (matrix_ethernet_conv[i,0] == matrix_ff[j,0]):\n",
    "\t\t\tconversation_size += int(matrix_ff[j,1])\n",
    "\tmatrix_ethernet_conv[i,1] = conversation_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(matrix_conversations)):\n",
    "\tconversation_size = 0\n",
    "\tfor j in range(len(matrix_fp[:,0])):\n",
    "\t\tif (matrix_conversations[i,0] == matrix_fp[j,0]):\n",
    "\t\t\tconversation_size += int(matrix_fp[j,1])\n",
    "\tmatrix_conversations[i,1] = conversation_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We create three vectors for Source, Destination and ConversationSize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_macs = []\n",
    "dst_macs = []\n",
    "con_macs = []\n",
    "for i in range (len(matrix_ethernet_conv)):\n",
    "\tmacs = matrix_conversations[i,0].split(\",\")\n",
    "\tsrc_macs.append(ips[0])\n",
    "\tdst_macs.append(ips[1])\n",
    "\tcon_macs.append(matrix_conversations[i,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_ips = []\n",
    "dst_ips = []\n",
    "con_siz = []\n",
    "for i in range (len(matrix_conversations)):\n",
    "\tips = matrix_conversations[i,0].split(\",\")\n",
    "\tsrc_ips.append(ips[0])\n",
    "\tdst_ips.append(ips[1])\n",
    "\tcon_siz.append(matrix_conversations[i,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_macs_copy = copy.deepcopy(src_macs)\n",
    "dst_macs_copy = copy.deepcopy(dst_macs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_ips_copy = copy.deepcopy(src_ips)\n",
    "dst_ips_copy = copy.deepcopy(dst_ips)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We create a dictionary of the conversation with prefix PC<number>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "mac_values = src_macs + dst_macs\n",
    "mac_values = list(set(mac_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "ip_values = src_ips + dst_ips\n",
    "ip_values = list(set(ip_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_labels2 = []\n",
    "for i in range (1, len(mac_values) + 1):\n",
    "\tprefix = \"PC\" + str(i)\n",
    "\tpc_labels2.append(prefix)\n",
    "mac_dict = dict(zip(mac_values, pc_labels2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_labels = []\n",
    "for i in range (1, len(ip_values) + 1):\n",
    "\tprefix = \"PC\" + str(i)\n",
    "\tpc_labels.append(prefix)\n",
    "conversation_dict = dict(zip(ip_values, pc_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We substitute IP values for their respective key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in src_macs:\n",
    "\tindex = src_macs.index(item)\n",
    "\tsrc_macs[index] = mac_dict.get(item)\n",
    "for item in dst_macs:\n",
    "\tindex = dst_macs.index(item)\n",
    "\tdst_macs[index] = mac_dict.get(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in src_ips:\n",
    "\tindex = src_ips.index(item)\n",
    "\tsrc_ips[index] = conversation_dict.get(item)\n",
    "for item in dst_ips:\n",
    "\tindex = dst_ips.index(item)\n",
    "\tdst_ips[index] = conversation_dict.get(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We create the Digraph of IPv4 Conversations and Ethernet Conversations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "dotether = graphviz.Digraph(comment='Ethernet Conversations')\n",
    "dotether.engine = \"twopi\" #doctest: +ELLIPSIS\n",
    "dotether #doctest: +ELLIPSIS\n",
    "dotether.graph_attr['ranksep']='2'\t\t#separation between center (twopi engine)\n",
    "dotether.graph_attr['nodesep']='0.5'\t\t#separation between arrows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "dotipv4 = graphviz.Digraph(comment='IPv4 Conversations')\n",
    "dotipv4.engine = \"twopi\" #doctest: +ELLIPSIS\n",
    "dotipv4 #doctest: +ELLIPSIS\n",
    "dotipv4.graph_attr['ranksep']='2'\t\t#separation between center (twopi engine)\n",
    "dotipv4.graph_attr['nodesep']='0.5'\t\t#separation between arrows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We first create the Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in mac_dict.items():\n",
    "\tdotether.node(key, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in conversation_dict.items():\n",
    "\tdotipv4.node(key, value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We now add the edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['659', '1454', '2631', '15182']"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con_macs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[659, 1454, 2631, 15182]"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con_siz_int2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15182"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5008607037113544"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.000757419265991875"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0, 1.6021483164635406, 2.4936307925359773, 12.0]"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapped_con_size2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First we create a linear map of the conversation size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "con_siz_int2 = list(map(int, con_macs))\n",
    "A2 = min(con_siz_int2)\n",
    "B2 = max(con_siz_int2)\n",
    "P2 = 1  # thinest edge\n",
    "Q2 = 12  # thickest edge\n",
    "b2 = (Q2 - P2) / (B2 - A2)\n",
    "a2 = P2 - b2 * A2\n",
    "mapped_con_size2 = [a2 + b2 * x for x in con_siz_int2]\n",
    "str_map_con_size2 = list(map(str, mapped_con_size2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "con_siz_int = list(map(int, con_siz))\n",
    "A = min(con_siz_int)\n",
    "B = max(con_siz_int)\n",
    "P = 1  # thinest edge\n",
    "Q = 12  # thickest edge\n",
    "b = (Q - P) / (B - A)\n",
    "a = P - b * A\n",
    "mapped_con_size = [a + b * x for x in con_siz_int]\n",
    "str_map_con_size = list(map(str, mapped_con_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "readable_size = []\n",
    "for item in con_siz_int:\n",
    "\tunits_size = 1\n",
    "\tcounter = 0\n",
    "\twhile (item / (1000 * units_size) > 1):\n",
    "\t\tunits_size = units_size * 1000\n",
    "\t\tcounter += 1\n",
    "\toutput = item / units_size\n",
    "\tif (counter == 0):\n",
    "\t\tprefix = \"B\"\n",
    "\telif (counter == 1):\n",
    "\t\tprefix = \"KB\"\n",
    "\telif (counter == 2):\n",
    "\t\tprefix = \"MB\"\n",
    "\telif (counter == 3):\n",
    "\t\tprefix = \"GB\"\n",
    "\telif (counter == 4):\n",
    "\t\tprefix = \"TB\"\n",
    "\tif (counter == 0):\n",
    "\t\tread = str(int(output)) + \" \" + prefix\n",
    "\telse:\n",
    "\t\tread = \"{:.2f}\".format(output) + \" \" + prefix\n",
    "\treadable_size.append(read)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(src_macs_copy)):\n",
    "\tdotether.edge(src_macs_copy[i], dst_macs_copy[i], penwidth=str_map_con_size2[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(src_ips_copy)):\n",
    "\tdotipv4.edge(src_ips_copy[i], dst_ips_copy[i], penwidth=str_map_con_size[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rendering the image of the ipv4 conversation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'test-output\\\\conversation-ether.gv.svg'"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dotether.format = 'svg'\n",
    "dotether.render('test-output/conversation-ether.gv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'test-output\\\\conversation-ipv4.gv.svg'"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "dotipv4.format = 'svg'\n",
    "dotipv4.render('test-output/conversation-ipv4.gv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'test-output/conversation-ether.gv.svg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'test-output/conversation-ipv4.gv.svg'"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'test-output/conversation-ipv4.gv.svg'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We make an create a dictionary of ocurrences (relevant for analysis of frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_occurrences = []\n",
    "value_ocurrences = []\n",
    "for key, value in conversation_dict.items():\n",
    "\tcounter = 0\n",
    "\tkey_occurrences.append(value)\n",
    "\tfor item in src_ips_copy:\n",
    "\t\tcounter = counter + 1 if (key == item) else counter\n",
    "\tvalue_ocurrences.append(counter)\n",
    "occurrences_dict = dict(zip(key_occurrences, value_ocurrences))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "63fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d"
  },
  "kernelspec": {
   "display_name": "nap_venv",
   "language": "python",
   "name": "nap_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
