{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We start by importing the relevant libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available Themes: \r\n",
      "   chesterish\r\n",
      "   grade3\r\n",
      "   gruvboxd\r\n",
      "   gruvboxl\r\n",
      "   monokai\r\n",
      "   oceans16\r\n",
      "   onedork\r\n",
      "   solarizedd\r\n",
      "   solarizedl\r\n"
     ]
    }
   ],
   "source": [
    "!jt -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We start by importing the relevant libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scapy.all as scapy\n",
    "import numpy as np \n",
    "import graphviz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We load the pcap file and split it into Packets and Frames:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0:1'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10612/4180136061.py:11: VisibleDeprecationWarning: Creating an ndarray from nested sequences exceeding the maximum number of dimensions of 32 is deprecated. If you mean to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  packet_list = np.array(packet_list)\n"
     ]
    }
   ],
   "source": [
    "all_traffic = scapy.rdpcap(\"./pcap/network-traffic.pcap\")\n",
    "packet_list = []\t\t# to store layer 3 traffic\n",
    "filt = []\n",
    "for pkt in all_traffic:\n",
    "    if pkt.haslayer('IP'):\n",
    "        filt.append([pkt['IP']])\n",
    "filtered = (pkt for pkt in all_traffic if IP in pkt)\n",
    "for packet in all_traffic:\n",
    "    if (scapy.IP in packet):\n",
    "        packet_list.append([packet['IP']])\n",
    "packet_list = np.array(packet_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[<IP  version=4 ihl=5 tos=0x0 len=61 id=38507 flags=DF frag=0 ttl=64 proto=udp chksum=0x6750 src=10.138.38.223 dst=10.139.1.1 |<UDP  sport=53822 dport=domain len=41 chksum=0x3d2f |<DNS  id=63604 qr=0 opcode=QUERY aa=0 tc=0 rd=1 ra=0 z=0 ad=0 cd=0 rcode=ok qdcount=1 ancount=0 nscount=0 arcount=0 qd=<DNSQR  qname='www.tor2web.org.' qtype=A qclass=IN |> an=None ns=None ar=None |>>>]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]\n",
      "658\n",
      "[<IP  version=4 ihl=5 tos=0x0 len=61 id=38507 flags=DF frag=0 ttl=64 proto=udp chksum=0x6750 src=10.138.38.223 dst=10.139.1.1 |<UDP  sport=53822 dport=domain len=41 chksum=0x3d2f |<DNS  id=63604 qr=0 opcode=QUERY aa=0 tc=0 rd=1 ra=0 z=0 ad=0 cd=0 rcode=ok qdcount=1 ancount=0 nscount=0 arcount=0 qd=<DNSQR  qname='www.tor2web.org.' qtype=A qclass=IN |> an=None ns=None ar=None |>>>]\n",
      "658\n"
     ]
    }
   ],
   "source": [
    "print(packet_list[0])\n",
    "print(len(packet_list))\n",
    "print(filt[0])\n",
    "print(len(filt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dot\n",
      "twopi\n",
      "neato\n",
      "circo\n"
     ]
    }
   ],
   "source": [
    "engines = [\"dot\", \"twopi\", \"neato\", \"circo\"]\n",
    "for item in engines:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify the conversation (communication between end points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_packets = list(set(packet_list[:,0]))\n",
    "conv_frames = list(set(frame_list[:,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[<Ether  dst=fe:ff:ff:ff:ff:ff src=00:16:3e:5e:6c:00 type=IPv4 |<IP  version=4 ihl=5 tos=0x0 len=61 id=38507 flags=DF frag=0 ttl=64 proto=udp chksum=0x6750 src=10.138.38.223 dst=10.139.1.1 |<UDP  sport=53822 dport=domain len=41 chksum=0x3d2f |<DNS  id=63604 qr=0 opcode=QUERY aa=0 tc=0 rd=1 ra=0 z=0 ad=0 cd=0 rcode=ok qdcount=1 ancount=0 nscount=0 arcount=0 qd=<DNSQR  qname='www.tor2web.org.' qtype=A qclass=IN |> an=None ns=None ar=None |>>>>]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]\n"
     ]
    }
   ],
   "source": [
    "print(packet_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_layer3 = np.transpose(np.array([conv_packets, [0] * len(conv_packets)]))\n",
    "matrix_layer2 = np.transpose(np.array([conv_frames, [0] * len(conv_frames)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculation of the conversation size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(conv_frames)):\n",
    "\tconversation_size = 0\n",
    "\tfor j in range(len(frame_list[:,0])):\n",
    "\t\tif (matrix_layer2[i,0] == frame_list[j,0]):\n",
    "\t\t\tconversation_size += int(frame_list[j,1])\n",
    "\tmatrix_layer2[i,1] = conversation_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(conv_packets)):\n",
    "\tconversation_size = 0\n",
    "\tfor j in range(len(packet_list[:,0])):\n",
    "\t\tif (matrix_layer3[i,0] == packet_list[j,0]):\n",
    "\t\t\tconversation_size += int(packet_list[j,1])\n",
    "\tmatrix_layer3[i,1] = conversation_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We create three vectors for Source, Destination and ConversationSize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_macs = []\n",
    "dst_macs = []\n",
    "con_macs = []\n",
    "for i in range (len(matrix_layer2)):\n",
    "\tmacs = matrix_layer2[i,0].split(\",\")\n",
    "\tsrc_macs.append(macs[0])\n",
    "\tdst_macs.append(macs[1])\n",
    "\tcon_macs.append(matrix_layer2[i,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['126', '70', '126', '70']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con_macs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_ips = []\n",
    "dst_ips = []\n",
    "con_siz = []\n",
    "for i in range (len(matrix_layer3)):\n",
    "\tips = matrix_layer3[i,0].split(\",\")\n",
    "\tsrc_ips.append(ips[0])\n",
    "\tdst_ips.append(ips[1])\n",
    "\tcon_siz.append(matrix_layer3[i,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We create a dictionary of the conversation with prefix PC<number>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "mac_values = list(set(src_macs + dst_macs))\n",
    "ip_values = list(set(src_ips + dst_ips))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_labels2 = []\n",
    "for i in range (1, len(mac_values) + 1):\n",
    "\tprefix = \"MAC\" + str(i)\n",
    "\tpc_labels2.append(prefix)\n",
    "mac_dict = dict(zip(mac_values, pc_labels2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_labels = []\n",
    "for i in range (1, len(ip_values) + 1):\n",
    "\tprefix = \"IP\" + str(i)\n",
    "\tpc_labels.append(prefix)\n",
    "conversation_dict = dict(zip(ip_values, pc_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We substitute IP values for their respective key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for item in src_macs:\n",
    "# \tindex = src_macs.index(item)\n",
    "# \tsrc_macs[index] = mac_dict.get(item)\n",
    "# for item in dst_macs:\n",
    "# \tindex = dst_macs.index(item)\n",
    "# \tdst_macs[index] = mac_dict.get(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for item in src_ips:\n",
    "# \tindex = src_ips.index(item)\n",
    "# \tsrc_ips[index] = conversation_dict.get(item)\n",
    "# for item in dst_ips:\n",
    "# \tindex = dst_ips.index(item)\n",
    "# \tdst_ips[index] = conversation_dict.get(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We create the Digraph of IPv4 Conversations and Ethernet Conversations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dotether = graphviz.Digraph(comment='Ethernet Conversations')\n",
    "dotether.engine = \"twopi\" #doctest: +ELLIPSIS\n",
    "dotether.graph_attr['ranksep']='2'\t\t#separation between center (twopi engine)\n",
    "dotether.graph_attr['nodesep']='0.5'\t\t#separation between arrows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in mac_dict.items():\n",
    "\tdotether.node(key, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['126', '70', '126', '70']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con_macs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "con_siz_int2 = list(map(int, con_macs))\n",
    "A2 = min(con_siz_int2)\n",
    "B2 = max(con_siz_int2)\n",
    "P2 = 1  # thinest edge\n",
    "Q2 = 12  # thickest edge\n",
    "b2 = (Q2 - P2) / (B2 - A2)\n",
    "a2 = P2 - b2 * A2\n",
    "mapped_con_size2 = [a2 + b2 * x for x in con_siz_int2]\n",
    "str_map_con_size2 = list(map(str, mapped_con_size2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['12.0', '1.0', '12.0', '1.0']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str_map_con_size2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(src_macs)):\n",
    "\tdotether.edge(src_macs[i], dst_macs[i], penwidth=str_map_con_size2[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: syntax ambiguity - badly delimited number '3e' in line 7 of conversation-ether.gv splits into two tokens\n",
      "Warning: syntax ambiguity - badly delimited number '5e' in line 7 of conversation-ether.gv splits into two tokens\n",
      "Warning: syntax ambiguity - badly delimited number '6c' in line 7 of conversation-ether.gv splits into two tokens\n",
      "Error: conversation-ether.gv: syntax error in line 7 near ':'\n"
     ]
    },
    {
     "ename": "CalledProcessError",
     "evalue": "Command '[WindowsPath('dot'), '-Ktwopi', '-Tsvg', '-O', 'conversation-ether.gv']' returned non-zero exit status 1. [stderr: b\"Warning: syntax ambiguity - badly delimited number '3e' in line 7 of conversation-ether.gv splits into two tokens\\r\\nWarning: syntax ambiguity - badly delimited number '5e' in line 7 of conversation-ether.gv splits into two tokens\\r\\nWarning: syntax ambiguity - badly delimited number '6c' in line 7 of conversation-ether.gv splits into two tokens\\r\\nError: conversation-ether.gv: syntax error in line 7 near ':'\\r\\n\"]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32md:\\python_projects\\nap\\venv\\lib\\site-packages\\graphviz\\backend\\execute.py\u001b[0m in \u001b[0;36mrun_check\u001b[1;34m(cmd, input_lines, encoding, capture_output, quiet, **kwargs)\u001b[0m\n\u001b[0;32m     94\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 95\u001b[1;33m         \u001b[0mproc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_returncode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     96\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0msubprocess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCalledProcessError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python39\\lib\\subprocess.py\u001b[0m in \u001b[0;36mcheck_returncode\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    459\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 460\u001b[1;33m             raise CalledProcessError(self.returncode, self.args, self.stdout,\n\u001b[0m\u001b[0;32m    461\u001b[0m                                      self.stderr)\n",
      "\u001b[1;31mCalledProcessError\u001b[0m: Command '[WindowsPath('dot'), '-Ktwopi', '-Tsvg', '-O', 'conversation-ether.gv']' returned non-zero exit status 1.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_20496/435303646.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mdotether\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'svg'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdotether\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'test-output/conversation-ether.gv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32md:\\python_projects\\nap\\venv\\lib\\site-packages\\graphviz\\rendering.py\u001b[0m in \u001b[0;36mrender\u001b[1;34m(self, filename, directory, view, cleanup, format, renderer, formatter, quiet, quiet_view, engine)\u001b[0m\n\u001b[0;32m     81\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 83\u001b[1;33m         \u001b[0mrendered\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_render\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcleanup\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\python_projects\\nap\\venv\\lib\\site-packages\\graphviz\\backend\\rendering.py\u001b[0m in \u001b[0;36mrender\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m     60\u001b[0m         \u001b[0mcwd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 62\u001b[1;33m     \u001b[0mexecute\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_check\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcapture_output\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcwd\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcwd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mquiet\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mquiet\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     63\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mrendered\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\python_projects\\nap\\venv\\lib\\site-packages\\graphviz\\backend\\execute.py\u001b[0m in \u001b[0;36mrun_check\u001b[1;34m(cmd, input_lines, encoding, capture_output, quiet, **kwargs)\u001b[0m\n\u001b[0;32m     95\u001b[0m         \u001b[0mproc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_returncode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0msubprocess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCalledProcessError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 97\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mCalledProcessError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     98\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mproc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mCalledProcessError\u001b[0m: Command '[WindowsPath('dot'), '-Ktwopi', '-Tsvg', '-O', 'conversation-ether.gv']' returned non-zero exit status 1. [stderr: b\"Warning: syntax ambiguity - badly delimited number '3e' in line 7 of conversation-ether.gv splits into two tokens\\r\\nWarning: syntax ambiguity - badly delimited number '5e' in line 7 of conversation-ether.gv splits into two tokens\\r\\nWarning: syntax ambiguity - badly delimited number '6c' in line 7 of conversation-ether.gv splits into two tokens\\r\\nError: conversation-ether.gv: syntax error in line 7 near ':'\\r\\n\"]"
     ]
    }
   ],
   "source": [
    "dotether.format = 'svg'\n",
    "dotether.render('test-output/conversation-ether.gv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'test-output/conversation-ether.gv.svg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dotipv4 = graphviz.Digraph(comment='IPv4 Conversations')\n",
    "# dotipv4.engine = \"twopi\" #doctest: +ELLIPSIS\n",
    "# dotipv4 #doctest: +ELLIPSIS\n",
    "# dotipv4.graph_attr['ranksep']='2'\t\t#separation between center (twopi engine)\n",
    "# dotipv4.graph_attr['nodesep']='0.5'\t\t#separation between arrows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for key, value in conversation_dict.items():\n",
    "# \tdotipv4.node(key, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# con_siz_int = list(map(int, con_siz))\n",
    "# A = min(con_siz_int)\n",
    "# B = max(con_siz_int)\n",
    "# P = 1  # thinest edge\n",
    "# Q = 12  # thickest edge\n",
    "# b = (Q - P) / (B - A)\n",
    "# a = P - b * A\n",
    "# mapped_con_size = [a + b * x for x in con_siz_int]\n",
    "# mapped_con_size= list(map(str, mapped_con_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len(src_ips)):\n",
    "# \tdotipv4.edge(src_ips[i], dst_ips[i], penwidth=str_map_con_size[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dotipv4.format = 'svg'\n",
    "# dotipv4.render('test-output/conversation-ipv4.gv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'test-output/conversation-ipv4.gv.svg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# readable_size = []\n",
    "# for item in con_siz_int:\n",
    "# \tunits_size = 1\n",
    "# \tcounter = 0\n",
    "# \twhile (item / (1000 * units_size) > 1):\n",
    "# \t\tunits_size = units_size * 1000\n",
    "# \t\tcounter += 1\n",
    "# \toutput = item / units_size\n",
    "# \tif (counter == 0):\n",
    "# \t\tprefix = \"B\"\n",
    "# \telif (counter == 1):\n",
    "# \t\tprefix = \"KB\"\n",
    "# \telif (counter == 2):\n",
    "# \t\tprefix = \"MB\"\n",
    "# \telif (counter == 3):\n",
    "# \t\tprefix = \"GB\"\n",
    "# \telif (counter == 4):\n",
    "# \t\tprefix = \"TB\"\n",
    "# \tif (counter == 0):\n",
    "# \t\tread = str(int(output)) + \" \" + prefix\n",
    "# \telse:\n",
    "# \t\tread = \"{:.2f}\".format(output) + \" \" + prefix\n",
    "# \treadable_size.append(read)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We make an create a dictionary of ocurrences (relevant for analysis of frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# key_occurrences = []\n",
    "# value_ocurrences = []\n",
    "# for key, value in conversation_dict.items():\n",
    "# \tcounter = 0\n",
    "# \tkey_occurrences.append(value)\n",
    "# \tfor item in src_ips_copy:\n",
    "# \t\tcounter = counter + 1 if (key == item) else counter\n",
    "# \tvalue_ocurrences.append(counter)\n",
    "# occurrences_dict = dict(zip(key_occurrences, value_ocurrences))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "63fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
